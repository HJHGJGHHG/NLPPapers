# Bring NLP to Edge
One trend in AI  is to deploy high performance models on mobile/embedded devices.  
Challenges: ***low memory resources***, ***low processor performance*** --> how to design lightweight models?  
Running neural networks on resource-constrained devices requires joint solutions from data engineering and data science: (figure from [[Song Han class]](https://www.youtube.com/watch?v=eZdOkDtYMoo))  

<center><img src="1.png"  style="zoom:100%;" width="110%"/></center>

## Surveys & Overview
* **Bringing AI To Edge: From Deep Learning's Perspective**  *Di Liu, Hao Kong, Xiangzhong Luo, Weichen Liu, Ravi Subramaniam*  [[pdf]](https://arxiv.org/pdf/2011.14808.pdf)

## [Efficient Model Architectures](https://github.com/HJHGJGHHG/NLPPapers/tree/main/PLM/Computational%20Efficiency/Efficient%20Model%20Architectures)
Reduce the computational complexity of transformer. TODO  